{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oiC86vqX9Qfk"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "\n",
        "def calculate_angle(a, b, c):\n",
        "    a = np.array(a)  # First\n",
        "    b = np.array(b)  # Mid\n",
        "    c = np.array(c)  # End\n",
        "    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])\n",
        "    angle = np.abs(radians * 180.0 / np.pi)\n",
        "    if angle > 180.0:\n",
        "        angle = 360 - angle\n",
        "    return angle\n",
        "\n",
        "def rescale_frame(frame, percent=50):\n",
        "    width = int(frame.shape[1] * percent / 100)\n",
        "    height = int(frame.shape[0] * percent / 100)\n",
        "    dim = (width, height)\n",
        "    return cv2.resize(frame, dim, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "columns = ['video file','frame number', 'transition', 'trunk angle', 'trunk acceleration']\n",
        "log_df = pd.DataFrame(columns=columns)\n",
        "\n",
        "columns_keypoints = ['video_name', 'frame_number', 'keypoint', 'x_coordinate', 'y_coordinate', 'visibility_score']\n",
        "keypoints_df = pd.DataFrame(columns=columns_keypoints)\n",
        "\n",
        "import os\n",
        "\n",
        "video_folder = \"C:/Users/Downloads/20\"\n",
        "results_folder = \"C:/Users/Downloads/white\"\n",
        "os.makedirs(results_folder, exist_ok=True)\n",
        "video_files = [f for f in os.listdir(video_folder) if f.endswith('.mp4')]\n",
        "for video_file in video_files:\n",
        "    video_path = os.path.join(video_folder, video_file)\n",
        "    output_video_path = os.path.join(results_folder, f'output_{video_file}')\n",
        "\n",
        "    model = YOLO('./models/yolov8m-pose.pt')\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    output_video = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "    previous_angle = 95\n",
        "    transition_time_sit_to_stand = 0\n",
        "    transition_time_stand_to_sit = 0\n",
        "    transition_state = 'sitting'\n",
        "    total_time_sitting = 0\n",
        "    total_time_standing = 0\n",
        "    total_time_walking = 0\n",
        "    last_state = 'sitting'\n",
        "\n",
        "    prev_trunk_angle = 0\n",
        "    trunk_velocity = 0\n",
        "\n",
        "    keypoint_ids = {0:'Nose', 1:'Left Eye', 2:'Right Eye', 3:'Left Ear', 4:'Right Ear', 5:'Left Shoulder', 6:'Right Shoulder', 7:'Left Elbow', 8:'Right Elbow', 9:'Left Wrist', 10:'Right Wrist', 11:'Left Hip', 12:'Right Hip', 13:'Left Knee', 14:'Right Knee', 15:'Left Ankle', 16:'Right Ankle'}\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        results = model(frame)\n",
        "        if results is None:\n",
        "            print(\"No objects detected in the frame.\")\n",
        "            continue  # Skip frames where no objects are detected\n",
        "\n",
        "        confidence = results[0].keypoints.conf[0].numpy()\n",
        "        keypoints = results[0].keypoints.xy[0].numpy()\n",
        "\n",
        "        count = 0\n",
        "        for idx, point in enumerate(keypoints):\n",
        "            x, y = map(int, point)\n",
        "            keypoints_df = keypoints_df._append({'video_name': video_file, 'frame_number': cap.get(cv2.CAP_PROP_POS_FRAMES), 'keypoint': keypoint_ids[int(idx)], 'x_coordinate': x, 'y_coordinate': y, 'visibility_score':confidence[int(idx)]}, ignore_index=True)\n",
        "\n",
        "            cv2.circle(frame, (x, y), 5, (0, 255, 0), -1)\n",
        "            if count == 5:\n",
        "                left_shoulder = [x,y]\n",
        "            elif count == 6:\n",
        "                right_shoulder = [x,y]\n",
        "            elif count == 11:\n",
        "                left_hip = [x,y]\n",
        "            elif count == 12:\n",
        "                right_hip = [x,y]\n",
        "            elif count == 13:\n",
        "                left_knee = [x,y]\n",
        "            elif count == 14:\n",
        "                right_knee = [x,y]\n",
        "            elif count == 15:\n",
        "                left_ankle = [x,y]\n",
        "            elif count == 16:\n",
        "                right_ankle = [x,y]\n",
        "            count += 1\n",
        "            cv2.circle(frame, (x, y), 5, (0, 255, 0), -1)\n",
        "\n",
        "        distance_threshold = 50\n",
        "        distance_ankles = np.sqrt((left_ankle[0] - right_ankle[0])**2 + (left_ankle[1] - right_ankle[1])**2)\n",
        "\n",
        "        angle_left_knee = calculate_angle(left_hip, left_knee, left_ankle)\n",
        "        angle_left_knee = round(angle_left_knee,2)\n",
        "\n",
        "        angle_right_knee = calculate_angle(right_hip, right_knee, right_ankle)\n",
        "        angle_right_knee = round(angle_right_knee, 2)\n",
        "\n",
        "        angle_left_hip = calculate_angle(left_shoulder, left_hip, left_knee)\n",
        "        angle_left_hip = round(angle_left_hip, 2)\n",
        "\n",
        "        angle_right_hip = calculate_angle(right_shoulder, right_hip, right_knee)\n",
        "        angle_right_hip = round(angle_right_hip, 2)\n",
        "\n",
        "        left_hip_angle = 180-angle_left_hip\n",
        "        left_knee_angle = 180-angle_left_knee\n",
        "\n",
        "        right_hip_angle = 180-angle_right_hip\n",
        "        right_knee_angle = 180-angle_right_knee\n",
        "\n",
        "        trunk_angle_left = calculate_angle(left_shoulder, left_hip, left_knee)\n",
        "        trunk_angle_right = calculate_angle(right_shoulder, right_hip, right_knee)\n",
        "\n",
        "        trunk_angle = (trunk_angle_left + trunk_angle_right)/2\n",
        "        trunk_angle = round(trunk_angle, 2)\n",
        "        print(\"Trunk Angle:\", trunk_angle)\n",
        "\n",
        "        trunk_acceleration = round(abs(trunk_angle - prev_trunk_angle), 2)\n",
        "        prev_trunk_angle = trunk_angle\n",
        "\n",
        "        cv2.putText(frame, f\"Trunk Angle: {trunk_angle}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "        cv2.putText(frame, f\"Trunk Acceleration: {trunk_acceleration}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "\n",
        "        if 105 < trunk_angle < 150:\n",
        "            if trunk_angle > previous_angle:\n",
        "                transition_state = \"sit to stand\"\n",
        "                transition_time_sit_to_stand += 1 / fps\n",
        "                log_entry = {'video name': video_file, 'frame number': cap.get(cv2.CAP_PROP_POS_FRAMES), 'transition': transition_state, 'trunk angle': trunk_angle, 'trunk acceleration': trunk_acceleration}\n",
        "                log_df = log_df._append(log_entry, ignore_index=True)\n",
        "                last_state = transition_state\n",
        "            elif trunk_angle < previous_angle:\n",
        "                transition_state = \"stand to sit\"\n",
        "                transition_time_stand_to_sit+= 1 / fps\n",
        "                log_entry = {'video name': video_file, 'frame number': cap.get(cv2.CAP_PROP_POS_FRAMES), 'transition': transition_state, 'trunk angle': trunk_angle, 'trunk acceleration': trunk_acceleration}\n",
        "                log_df = log_df._append(log_entry, ignore_index=True)\n",
        "                last_state = transition_state\n",
        "\n",
        "        elif 90 < trunk_angle < 105:\n",
        "            if last_state == \"stand to sit\":\n",
        "                if distance_ankles < distance_threshold:\n",
        "                    transition_state = \"standing\"\n",
        "                else:\n",
        "                    transition_state = \"walking\"\n",
        "            else:\n",
        "                transition_state = \"sitting\"\n",
        "\n",
        "        elif 150 < trunk_angle < 180:\n",
        "            if distance_ankles < distance_threshold:\n",
        "                transition_state = \"standing\"\n",
        "            else:\n",
        "                transition_state = \"walking\"\n",
        "            last_state = transition_state\n",
        "\n",
        "        elif trunk_angle < 90:\n",
        "            if transition_state == \"sit to stand\" or transition_state == \"sitting\":\n",
        "                transition_time_sit_to_stand += 1 / fps\n",
        "                log_entry = {'video name': video_file, 'frame number': cap.get(cv2.CAP_PROP_POS_FRAMES), 'transition': \"sit to stand\", 'trunk angle': trunk_angle, 'trunk acceleration': trunk_acceleration}\n",
        "                log_df = log_df._append(log_entry, ignore_index=True)\n",
        "                last_state = transition_state\n",
        "            elif transition_state == \"stand to sit\" or transition_state == \"standing\":\n",
        "                transition_time_stand_to_sit += 1 / fps\n",
        "                log_entry = {'video name': video_file, 'frame number': cap.get(cv2.CAP_PROP_POS_FRAMES), 'transition': \"stand to sit\", 'trunk angle': trunk_angle, 'trunk acceleration': trunk_acceleration}\n",
        "                log_df = log_df._append(log_entry, ignore_index=True)\n",
        "                last_state = transition_state\n",
        "\n",
        "        previous_angle = trunk_angle\n",
        "\n",
        "        if transition_state == 'standing' or transition_state == 'stand to sit':\n",
        "            total_time_standing += 1 / fps\n",
        "\n",
        "        if transition_state == 'walking':\n",
        "            total_time_walking += 1 / fps\n",
        "\n",
        "        if transition_state == 'sitting' or  transition_state == 'sit to stand':\n",
        "            total_time_sitting += 1 / fps\n",
        "\n",
        "        cv2.putText(frame, f\"Total time spent standing: {round(total_time_standing, 2)}\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "        cv2.putText(frame, f\"Total time spent sitting: {round(total_time_sitting, 2)}\", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "        cv2.putText(frame, f\"Total time spent walking: {round(total_time_walking, 2)}\", (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "        cv2.putText(frame, f\"Transition time to sit: {round(transition_time_stand_to_sit, 2)} sec\", (10, 180), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "        cv2.putText(frame, f\"Transition time to stand: {round(transition_time_sit_to_stand, 2)} sec\", (10, 210), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "        output_video.write(frame)\n",
        "\n",
        "excel_file_path = \"C:/Users/white/logfile.xlsx\"\n",
        "log_df.to_excel(excel_file_path, index=False)\n",
        "\n",
        "excel_file_path_keypoints = \"C:/Users/white/keypoints.xlsx\"\n",
        "keypoints_df.to_excel(excel_file_path_keypoints, index=False)\n",
        "cap.release()\n",
        "output_video.release()\n"
      ]
    }
  ]
}